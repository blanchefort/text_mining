{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Динамическая квантизация BERT",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "13TwmHfRLbm8Fu3zmMFzt6-wMmDXRGgVU",
      "authorship_tag": "ABX9TyPpyFM26Y2QejNunfcZ7jEB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88936591e7194ca3bbfdc1c30c9f462f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ea32ebcbaa61471a8efdeb1222d77eaf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dde248df3a074e8c86da89fa403260b7",
              "IPY_MODEL_432b113138264ee89e2aeacf4584f098"
            ]
          }
        },
        "ea32ebcbaa61471a8efdeb1222d77eaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dde248df3a074e8c86da89fa403260b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9675e9c335f64b7bab19897aebd50347",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 661,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 661,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80e5c829afef4a8597edef423887a10f"
          }
        },
        "432b113138264ee89e2aeacf4584f098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6a367cf844fe4293820ad8a11bea0ed7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 661/661 [1:31:35&lt;00:00,  8.31s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed66dc18a97844d5bd2b28442f9be52b"
          }
        },
        "9675e9c335f64b7bab19897aebd50347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80e5c829afef4a8597edef423887a10f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a367cf844fe4293820ad8a11bea0ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed66dc18a97844d5bd2b28442f9be52b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blanchefort/text_mining/blob/master/dynamic_quantization_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suatEbFsl6N3",
        "colab_type": "text"
      },
      "source": [
        "## Динамическая квантизация BERT\n",
        "Дообученная модель BERT показывает очень хорошее качество при решении множества NLP-задач. Однако, её не всегда можно применить на практике из-за того, что модель очень большая и работает дастаточно медленно. В связи с этим было придумано несколько способов обойти это ограничение.\n",
        "\n",
        "Один из способов - метод Dynamic quantization, реализованный в новых версиях Pytorch. Суть метода заключается в том, что мы переводим параметры обученной модели из float в int8. Благодаря этому снижается размер модели и, естественно, уменьшаются вычислительные ресурсы, требуемые для работы модели.\n",
        "\n",
        "(Как будет видно ниже, для моей модели квантизация существенно уменьшила качество модели, поэтому в моём случае данный метод нельзя использовать. Но, сохраню блокнот как пример квантизации)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfgM0x2ZnkdP",
        "colab_type": "text"
      },
      "source": [
        "### Библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAX7paPQl3kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzSQEhUQnSMZ",
        "colab_type": "code",
        "outputId": "a9527073-f7cc-4d96-fa2b-5e8746fed318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "import random\n",
        "from random import randint\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import (TensorDataset,\n",
        "                              DataLoader,\n",
        "                              RandomSampler)\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from transformers import AutoConfig, AutoModelForSequenceClassification\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "SEED = 22\n",
        "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.benchmark = False\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device.type)\n",
        "if device.type == 'cuda':\n",
        "    print(torch.cuda.get_device_name(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlHg9hK-pGy1",
        "colab_type": "text"
      },
      "source": [
        "## Загрузка обученной модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BxyIQ1lpMUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# config\n",
        "config = AutoConfig.from_pretrained('/content/drive/My Drive/colab_data/leroymerlin/model/BERT_model')\n",
        "# tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('/content/drive/My Drive/colab_data/leroymerlin/model/BERT_model', pad_to_max_length=True)\n",
        "# model\n",
        "model = AutoModelForSequenceClassification.from_pretrained('/content/drive/My Drive/colab_data/leroymerlin/model/BERT_model', config=config)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6AIVTzGn_6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/colab_data/leroymerlin/to_classifier.csv')\n",
        "sentences = df.name.values\n",
        "labels = [category_index[i] for i in df.category_1.values]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zs2wIA1XwsRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "category_index = {'Водоснабжение': 8,\n",
        " 'Декор': 12,\n",
        " 'Инструменты': 4,\n",
        " 'Краски': 11,\n",
        " 'Кухни': 15,\n",
        " 'Напольные покрытия': 5,\n",
        " 'Окна и двери': 2,\n",
        " 'Освещение': 13,\n",
        " 'Плитка': 6,\n",
        " 'Сад': 9,\n",
        " 'Сантехника': 7,\n",
        " 'Скобяные изделия': 10,\n",
        " 'Столярные изделия': 1,\n",
        " 'Стройматериалы': 0,\n",
        " 'Хранение': 14,\n",
        " 'Электротовары': 3}\n",
        "category_index_inverted = dict(map(reversed, category_index.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQychParohhi",
        "colab_type": "text"
      },
      "source": [
        "## Проверка работы модели до квантизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeeeS2ZxqrAM",
        "colab_type": "code",
        "outputId": "2b35d3f9-d380-4a74-b9e5-098035f6dced",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "30e34b1da25e4a088f838b4427f1e406"
          ]
        }
      },
      "source": [
        "%%time\n",
        "#model.to(device)\n",
        "model.eval()\n",
        "\n",
        "predicts, grounds = [], []\n",
        "batch = 400\n",
        "\n",
        "for sku in tqdm(range(batch, len(df), batch)):\n",
        "    b_s = sentences[sku-batch:sku]\n",
        "    tokens = [tokenizer.encode(\n",
        "        sent, \n",
        "        add_special_tokens=True, \n",
        "        max_length=24, \n",
        "        pad_to_max_length='right') for sent in b_s]\n",
        "    tokens = torch.tensor(tokens).to(device)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(tokens)\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    predicts.extend(preds)\n",
        "    grounds.extend(labels[sku-batch:sku])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30e34b1da25e4a088f838b4427f1e406",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=661), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 3h 35min 7s, sys: 1min 21s, total: 3h 36min 28s\n",
            "Wall time: 1h 48min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXoS0dAM0NXI",
        "colab_type": "code",
        "outputId": "7cd1ee9d-e99b-4ea5-d4b8-132d4da5be9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "print(classification_report(grounds, predicts, target_names=category_index_inverted.values()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "     Водоснабжение       0.94      0.88      0.91     13377\n",
            "             Декор       1.00      0.40      0.57      2716\n",
            "       Инструменты       1.00      0.40      0.58       540\n",
            "            Краски       0.97      0.81      0.88     20397\n",
            "             Кухни       0.96      0.91      0.93     29920\n",
            "Напольные покрытия       1.00      0.56      0.72      2555\n",
            "      Окна и двери       1.00      0.61      0.76      2440\n",
            "         Освещение       0.98      0.92      0.95     30560\n",
            "            Плитка       0.97      0.96      0.97     23922\n",
            "               Сад       0.95      0.98      0.96     49518\n",
            "        Сантехника       0.97      0.74      0.84     24245\n",
            "  Скобяные изделия       0.85      0.93      0.89     15280\n",
            " Столярные изделия       0.58      0.95      0.72     30329\n",
            "    Стройматериалы       0.98      0.67      0.80      8532\n",
            "          Хранение       0.97      0.77      0.86      6237\n",
            "     Электротовары       0.96      0.88      0.92      3832\n",
            "\n",
            "          accuracy                           0.89    264400\n",
            "         macro avg       0.94      0.77      0.83    264400\n",
            "      weighted avg       0.91      0.89      0.89    264400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACYWemJYu5hs",
        "colab_type": "text"
      },
      "source": [
        "# Квантизация"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjCz8SsHrpdz",
        "colab_type": "code",
        "outputId": "a5ec676c-44ae-4a1f-f5d8-6a0fe052f55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "model.to('cpu')\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.41 s, sys: 355 ms, total: 1.77 s\n",
            "Wall time: 1.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ML8OU0Ukvedd",
        "colab_type": "text"
      },
      "source": [
        "## Проверим размеры модели до и после квантизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH5hvrhbrtqM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_size_of_model(model):\n",
        "    torch.save(model.state_dict(), \"temp.p\")\n",
        "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
        "    os.remove('temp.p')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw8x9_QiviaU",
        "colab_type": "code",
        "outputId": "d90ba952-4183-4aab-a4ee-3c0a5daae389",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print_size_of_model(model)\n",
        "print_size_of_model(quantized_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size (MB): 711.508154\n",
            "Size (MB): 454.93095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i88xmoJPAxny",
        "colab_type": "text"
      },
      "source": [
        "## Проверка работы модели после квантизации"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv9IOP8xvlv9",
        "colab_type": "code",
        "outputId": "24382fc7-d425-4df1-cac5-6e4de1b57ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "88936591e7194ca3bbfdc1c30c9f462f",
            "ea32ebcbaa61471a8efdeb1222d77eaf",
            "dde248df3a074e8c86da89fa403260b7",
            "432b113138264ee89e2aeacf4584f098",
            "9675e9c335f64b7bab19897aebd50347",
            "80e5c829afef4a8597edef423887a10f",
            "6a367cf844fe4293820ad8a11bea0ed7",
            "ed66dc18a97844d5bd2b28442f9be52b"
          ]
        }
      },
      "source": [
        "%%time\n",
        "quantized_model.eval()\n",
        "\n",
        "predicts, grounds = [], []\n",
        "batch = 400\n",
        "\n",
        "for sku in tqdm(range(batch, len(df), batch)):\n",
        "    b_s = sentences[sku-batch:sku]\n",
        "    tokens = [tokenizer.encode(\n",
        "        sent, \n",
        "        add_special_tokens=True, \n",
        "        max_length=24, \n",
        "        pad_to_max_length='right') for sent in b_s]\n",
        "    tokens = torch.tensor(tokens)\n",
        "    with torch.no_grad():\n",
        "        outputs = quantized_model(tokens)\n",
        "    logits = outputs[0].detach().cpu().numpy()\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    predicts.extend(preds)\n",
        "    grounds.extend(labels[sku-batch:sku])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88936591e7194ca3bbfdc1c30c9f462f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=661), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "CPU times: user 3h 43s, sys: 1min 31s, total: 3h 2min 15s\n",
            "Wall time: 1h 31min 35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORm5U-ADwG_g",
        "colab_type": "code",
        "outputId": "18468653-f83a-4322-ed71-213e6777d8e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "print(classification_report(grounds, predicts, target_names=category_index_inverted.values()))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "     Водоснабжение       0.66      0.11      0.18     13377\n",
            "             Декор       0.00      0.00      0.00      2716\n",
            "       Инструменты       0.00      0.00      0.00       540\n",
            "            Краски       0.09      0.03      0.05     20397\n",
            "             Кухни       0.97      0.19      0.31     29920\n",
            "Напольные покрытия       0.86      0.06      0.11      2555\n",
            "      Окна и двери       0.77      0.04      0.08      2440\n",
            "         Освещение       0.97      0.05      0.09     30560\n",
            "            Плитка       0.89      0.32      0.47     23922\n",
            "               Сад       0.89      0.14      0.24     49518\n",
            "        Сантехника       0.72      0.03      0.06     24245\n",
            "  Скобяные изделия       0.81      0.17      0.28     15280\n",
            " Столярные изделия       0.13      0.97      0.23     30329\n",
            "    Стройматериалы       0.53      0.05      0.08      8532\n",
            "          Хранение       0.92      0.05      0.10      6237\n",
            "     Электротовары       0.63      0.09      0.16      3832\n",
            "\n",
            "          accuracy                           0.22    264400\n",
            "         macro avg       0.62      0.14      0.15    264400\n",
            "      weighted avg       0.70      0.22      0.20    264400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3McHYJthgxH",
        "colab_type": "text"
      },
      "source": [
        "Итак, мы видим, что после квантизации модель уменьшилась в полтора раза, а скорость предикта на CPU увеличилась лишь на 20%, при этом качество существенно снизилось. Возможно, нужно поэкспериментировать с различными параметрами квантизации. Но пока как пример оставим всё так."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cyV2JfgCUrl",
        "colab_type": "text"
      },
      "source": [
        "## Сохраним квантизованную модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_RTSxryBKzC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir '/content/drive/My Drive/colab_data/leroymerlin/model/BERT_quntized'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-7qYhU7Cs3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quantized_model.save_pretrained('/content/drive/My Drive/colab_data/leroymerlin/model/BERT_quntized')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}